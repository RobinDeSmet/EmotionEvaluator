FINDINGS
  - Applying stemming or lemmatization from nltk on the input text reduces the model's performance.
    This is because the model is able to generalize better with its own tokenizer.
  - Cleaning the data however can improve the model's performance.
  - Financial model will predict 'neutral' very often so the accuracy here is low!
  - Fastest model is from LiYuan
  - Most accurate model from NLPtown.
  - The model with the best tradeoffs is from Distilbert.
  - I use an ROC curve plot to calculate the AUC. But, I do it with the labels, as we have no output probability
    for the positive or negative class. Since, this is fixed, we cannot vary the decision threshold.
    Therefore the ROC curve does not hold any real value in this case. I should remove it.